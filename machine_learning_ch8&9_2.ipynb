{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.7"
    },
    "colab": {
      "name": "machine_learning_ch8&9_2.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/silverstar0727/1day-1commit-challenge/blob/master/machine_learning_ch8%269_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8a5w_u3tF1sq",
        "colab_type": "text"
      },
      "source": [
        "## IMBDb영화 리뷰"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jRoE7iaBF1st",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install pyprind"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YliYN_inF1sy",
        "colab_type": "code",
        "colab": {},
        "outputId": "95e8d324-4bea-4353-8106-b84b12450fa6"
      },
      "source": [
        "import pyprind\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "basepath = 'C:\\\\Users\\\\silve\\\\Desktop\\\\aclImdb_v1\\\\aclImdb'\n",
        "\n",
        "labels = {'pos': 1, 'neg': 0}\n",
        "pbar = pyprind.ProgBar(50000)\n",
        "\n",
        "df = pd.DataFrame()\n",
        "for s in('test', 'train'):\n",
        "    for l in ('pos', 'neg'):\n",
        "        path = os.path.join(basepath, s, l)\n",
        "        for file in sorted(os.listdir(path)):\n",
        "            with open(os.path.join(path, file), 'r', encoding = 'utf-8') as infile:\n",
        "                txt = infile.read()\n",
        "            df = df.append([[txt, labels[l]]], ignore_index = True)\n",
        "            pbar.update()\n",
        "            \n",
        "df.columns = ['review', 'sentiment']"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0% [##############################] 100% | ETA: 00:00:00\n",
            "Total time elapsed: 00:02:05\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cp0pezwhF1s4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "np.random.seed(0)\n",
        "df = df.reindex(np.random.permutation(df.index))\n",
        "df.to_csv('movie_data.csv', index = False, encoding = 'utf-8')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ymlG1bZrF1s9",
        "colab_type": "code",
        "colab": {},
        "outputId": "877c89ef-1c33-4a3c-db37-2bd866bed05e"
      },
      "source": [
        "df = pd.read_csv('movie_data.csv', encoding = 'utf-8')\n",
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>In 1974, the teenager Martha Moxley (Maggie Gr...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>OK... so... I really like Kris Kristofferson a...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>***SPOILER*** Do not read this, if you think a...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>hi for all the people who have seen this wonde...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>I recently bought the DVD, forgetting just how...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              review  sentiment\n",
              "0  In 1974, the teenager Martha Moxley (Maggie Gr...          1\n",
              "1  OK... so... I really like Kris Kristofferson a...          0\n",
              "2  ***SPOILER*** Do not read this, if you think a...          0\n",
              "3  hi for all the people who have seen this wonde...          1\n",
              "4  I recently bought the DVD, forgetting just how...          0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PFF8pjI7F1tD",
        "colab_type": "code",
        "colab": {},
        "outputId": "0787abd1-8446-4e5c-e8a7-37e609555257"
      },
      "source": [
        "df.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hMecolLNF1tJ",
        "colab_type": "text"
      },
      "source": [
        "### BOW model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e4UD2Q6VF1tK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# BoW 모델을 만듦\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "count = CountVectorizer()\n",
        "docs = np.array(['The sun is shining', 'The weather is sweet', \n",
        "                 'The sun is shining, the weater is sweet, and one and one is two'])\n",
        "\n",
        "bag = count.fit_transform(docs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4oAUqg1cF1tP",
        "colab_type": "text"
      },
      "source": [
        "CountVetorizer모듈에 내장되어 있는 vocabulary메소드 사용\n",
        "\n",
        "단어와 정수를 매핑하여 딕셔너리형태로 저장."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RI48T7SVF1tQ",
        "colab_type": "code",
        "colab": {},
        "outputId": "2ba098df-480c-4485-a3ba-e61c2d9e994d"
      },
      "source": [
        "print(count.vocabulary_)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'the': 6, 'sun': 4, 'is': 1, 'shining': 3, 'weather': 9, 'sweet': 5, 'weater': 8, 'and': 0, 'one': 2, 'two': 7}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iIQVdZu6F1tT",
        "colab_type": "code",
        "colab": {},
        "outputId": "44157c9a-d7de-4451-cc0d-43eb0f7d8272"
      },
      "source": [
        "print(bag.toarray())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0 1 0 1 1 0 1 0 0 0]\n",
            " [0 1 0 0 0 1 1 0 0 1]\n",
            " [2 3 2 1 1 1 2 1 1 0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lZ64H3DIF1tW",
        "colab_type": "text"
      },
      "source": [
        "## 단어의 적합성 평가\n",
        "tf-idf(term frequency-inverse document frequency)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DV6McXe2F1tX",
        "colab_type": "code",
        "colab": {},
        "outputId": "889511ed-52bc-4888-9523-9890cafd9c99"
      },
      "source": [
        "# 사이킷런의 TfidTransFormer클래스 사용\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "\n",
        "tfidf = TfidfTransformer(use_idf = True, norm = 'l2', smooth_idf = True)\n",
        "np.set_printoptions(precision = 2)\n",
        "print(tfidf.fit_transform(count.fit_transform(docs)).toarray())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.   0.43 0.   0.56 0.56 0.   0.43 0.   0.   0.  ]\n",
            " [0.   0.39 0.   0.   0.   0.5  0.39 0.   0.   0.66]\n",
            " [0.5  0.44 0.5  0.19 0.19 0.19 0.29 0.25 0.25 0.  ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V3AVqVl3F1ta",
        "colab_type": "code",
        "colab": {},
        "outputId": "17f07544-df5c-44af-a1f3-da1699446f99"
      },
      "source": [
        "df.loc[0, 'review'][-50:]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'is seven.<br /><br />Title (Brazil): Not Available'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EYygxLAEF1tc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 텍스트 데이터 정제\n",
        "import re\n",
        "\n",
        "def preprocessor(text):\n",
        "    text = re.sub('<[^>]*>', '', text)\n",
        "    emoticons = re.findall('(?::|;|=)(?:-)?(?:\\)|\\(|D|P)', text)\n",
        "    text = (re.sub('[\\W]+',' ', text.lower()) + ' '.join(emoticons).replace('-',''))\n",
        "    return text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HMCqkCJ1F1tf",
        "colab_type": "code",
        "colab": {},
        "outputId": "d143f657-5864-4fb7-8e4f-3b91d95745ce"
      },
      "source": [
        "preprocessor(df.loc[0, 'review'][-50:])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'is seven title brazil not available'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qtDfnDeOF1th",
        "colab_type": "code",
        "colab": {},
        "outputId": "8172e547-634a-492d-f266-0487b3b49bb4"
      },
      "source": [
        "preprocessor(\"<\\a>This :) is :( a test :-)!\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'this is a test :) :( :)'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dOZpQBueF1tk",
        "colab_type": "code",
        "colab": {},
        "outputId": "69097061-a867-40dd-e303-cec45bb3f62a"
      },
      "source": [
        "# 문서를 토큰으로 나누기\n",
        "def tokenizer(text):\n",
        "    return text.split()\n",
        "\n",
        "tokenizer('runners like running and thus they run')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['runners', 'like', 'running', 'and', 'thus', 'they', 'run']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2oQh647JF1tn",
        "colab_type": "code",
        "colab": {},
        "outputId": "d543d4d2-6567-4cff-ace0-02a1300909d0"
      },
      "source": [
        "from nltk.stem.porter import PorterStemmer\n",
        "porter = PorterStemmer()\n",
        "def tokenizer_porter(text):\n",
        "    return [porter.stem(word) for word in text.split()]\n",
        "tokenizer_porter('runners like running and thus they run')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['runner', 'like', 'run', 'and', 'thu', 'they', 'run']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vSzcSoE0F1tp",
        "colab_type": "code",
        "colab": {},
        "outputId": "c4578205-b76a-49e3-eee6-6929b111ade3"
      },
      "source": [
        "# 불용어집합을 다운로드\n",
        "import nltk\n",
        "\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     C:\\Users\\silve\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "huGnvSUOF1tr",
        "colab_type": "code",
        "colab": {},
        "outputId": "ca44ee54-aebc-4a4b-dd0f-dd2dd23fea5f"
      },
      "source": [
        "from nltk.corpus import stopwords\n",
        "\n",
        "stop = stopwords.words('english')\n",
        "\n",
        "[w for w in tokenizer_porter('a runner likes running and runs a lot')[-10:] if w not in stop]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['runner', 'like', 'run', 'run', 'lot']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SLEgxxsQF1tu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 문서분류를 위한 로지스틱 회귀 모델 훈련\n",
        "X_train = df.loc[:25000, 'review'].values\n",
        "y_train = df.loc[:25000, 'sentiment'].values\n",
        "X_test = df.loc[:25000, 'review'].values\n",
        "y_test = df.loc[:25000, 'sentiment'].values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-0ZibpYwF1tv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 40분 소요\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "tfidf = TfidfVectorizer(strip_accents = None, lowercase = False, preprocessor = None)\n",
        "param_grid = [{'vect__ngram_range': [(1,1)],\n",
        "              'vect__stop_words': [stop, None],\n",
        "              'vect__tokenizer': [tokenizer, tokenizer_porter],\n",
        "              'clf__penalty': ['l1', 'l2'],\n",
        "              'clf__C': [1.0, 10.0, 100.0]},\n",
        "             {'vect__ngram_range': [(1,1)],\n",
        "             'vect__stop_words': [tokenizer, tokenizer_porter],\n",
        "             'vect__use_idf': [False],\n",
        "             'vect__norm': [None],\n",
        "             'clf__penalty': ['l1', 'l2'],\n",
        "             'clf__C': [1.0, 10.0, 100.0]}]\n",
        "\n",
        "lr_tfidf = Pipeline([('vect', tfidf),\n",
        "                    ('clf', LogisticRegression(solver = 'liblinear', random_state = 0))])\n",
        "gs_lr_tfidf = GridSearchCV(lr_tfidf, param_grid, scoring = 'accuracy', cv = 5, verbose = 1, n_jobs = 1)\n",
        "gs_lr_tfidf.fit(X_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DwjLUhU7F1tx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('cv 정확도: %.3f' % gs_lr_tfidf.best_score_)\n",
        "clf = gs_lr_tfidf.best_estimator_\n",
        "print('테스트 정확도: %.3f' % clf.score(X_test, y_test))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p-1FXdRYF1t0",
        "colab_type": "text"
      },
      "source": [
        "# 대용량 데이터처리"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3_ifI9-sF1t0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#불용어를 제외한 단어토큰으로 분리\n",
        "import numpy as np\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "stop = stopwords.words('english')\n",
        "def tokenizer(text):\n",
        "    text = re.sub('<[^>]*>', '', text)\n",
        "    emoticons = re.findall('(?::|;|=)(?:-)?(?:\\)|\\(|D|P)', text)\n",
        "    text = (re.sub('[\\W]+',' ', text.lower()) + ' '.join(emoticons).replace('-',''))\n",
        "    tokenized = [w for w in text.split() if w not in stop]\n",
        "    return tokenized"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LvCCqG83F1t3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def stream_docs(path):\n",
        "    with open(path, 'r', encoding = 'utf-8') as csv:\n",
        "        next(csv) # 헤더 넘기기\n",
        "        for line in csv:\n",
        "            text, label = line[:-3], int(line[-2])\n",
        "            yield text, label"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RcvKsWhkF1t6",
        "colab_type": "code",
        "colab": {},
        "outputId": "ec16e529-1284-4f4e-d9cf-e588e2f85ae3"
      },
      "source": [
        "next(stream_docs(path = 'movie_data.csv'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('\"In 1974, the teenager Martha Moxley (Maggie Grace) moves to the high-class area of Belle Haven, Greenwich, Connecticut. On the Mischief Night, eve of Halloween, she was murdered in the backyard of her house and her murder remained unsolved. Twenty-two years later, the writer Mark Fuhrman (Christopher Meloni), who is a former LA detective that has fallen in disgrace for perjury in O.J. Simpson trial and moved to Idaho, decides to investigate the case with his partner Stephen Weeks (Andrew Mitchell) with the purpose of writing a book. The locals squirm and do not welcome them, but with the support of the retired detective Steve Carroll (Robert Forster) that was in charge of the investigation in the 70\\'s, they discover the criminal and a net of power and money to cover the murder.<br /><br />\"\"Murder in Greenwich\"\" is a good TV movie, with the true story of a murder of a fifteen years old girl that was committed by a wealthy teenager whose mother was a Kennedy. The powerful and rich family used their influence to cover the murder for more than twenty years. However, a snoopy detective and convicted perjurer in disgrace was able to disclose how the hideous crime was committed. The screenplay shows the investigation of Mark and the last days of Martha in parallel, but there is a lack of the emotion in the dramatization. My vote is seven.<br /><br />Title (Brazil): Not Available\"',\n",
              " 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OG-tlZXSF1t8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_minibatch(doc_stream, size):\n",
        "    docs, y = [],[]\n",
        "    try:\n",
        "        for _ in range(size):\n",
        "            text, label = next(doc_stream)\n",
        "            docs.append(text)\n",
        "            y.append(label)\n",
        "            \n",
        "    except StopIteration:\n",
        "        pass\n",
        "    return docs, y\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OQ0fUTRPF1t_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_extraction.text import HashingVectorizer\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "\n",
        "vect = HashingVectorizer(decode_error = 'ignore', n_features = 2**21, preprocessor = None, tokenizer = tokenizer)\n",
        "clf = SGDClassifier(loss = 'log', random_state = 1, max_iter = 1)\n",
        "doc_stream = stream_docs(path = 'movie_data.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pU4QNxoIF1uA",
        "colab_type": "code",
        "colab": {},
        "outputId": "56e939e2-2086-4682-d0c6-f8e6a50885aa"
      },
      "source": [
        "import pyprind\n",
        "\n",
        "pbar = pyprind.ProgBar(45)\n",
        "classes = np.array([0,1])\n",
        "\n",
        "for _ in range(45):\n",
        "    X_train, y_train = get_minibatch(doc_stream, size = 1000)\n",
        "    if not X_train:\n",
        "        break\n",
        "    \n",
        "    X_train = vect.transform(X_train)\n",
        "    clf.partial_fit(X_train, y_train, classes = classes)\n",
        "    pbar.update()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0% [##############################] 100% | ETA: 00:00:00\n",
            "Total time elapsed: 00:00:25\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tcyGFZGEF1uC",
        "colab_type": "code",
        "colab": {},
        "outputId": "5fcdf085-bec1-4f43-d0e8-d7dc71a4ab66"
      },
      "source": [
        "X_test, y_test = get_minibatch(doc_stream, size = 5000)\n",
        "X_test = vect.transform(X_test)\n",
        "\n",
        "print('정확도: %.3f' % clf.score(X_test, y_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "정확도: 0.868\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fqOUhBoSF1uF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "clf = clf.partial_fit(X_test, y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wfYac4Z7F1uH",
        "colab_type": "text"
      },
      "source": [
        "## 잠재 디리클레 할당을 사용한 토픽 모델링 (LDA)\n",
        "5장의 LDA와는 다름 (여기서의 LDA는 Latent Dirichlet Allocation)\n",
        "\n",
        "베이지안 추론에 대한 수학적 깊이가 필요함"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V1X5SMXsF1uI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 사이킷런의 LDA\n",
        "#데이터 읽기\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('movie_data.csv', encoding = 'utf-8')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rSrbl8suF1uK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# CountVectorizer 클래스를 이용하여 BoW행렬을 만들기\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "count = CountVectorizer(stop_words = 'english', max_df = .1, max_features = 5000) # 빈도가 높은 단어를 max_df를 통해 제외\n",
        "X = count.fit_transform(df['review'].values)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gE81wmHBF1uM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 문서에서 열개의 토픽을 추정하도록 LatentDirichletAllocation추정기를 BoW행렬에 학습하는 방법을 보여줌\n",
        "# 시간 오래걸림\n",
        "from sklearn.decomposition import LatentDirichletAllocation\n",
        "\n",
        "lda = LatentDirichletAllocation(n_components = 10, random_state = 123, learning_method = 'batch')\n",
        "X_topics = lda.fit_transform(X)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wuEfjcU8F1uO",
        "colab_type": "code",
        "colab": {},
        "outputId": "76f384fa-05aa-4b0d-a4e9-0c23f32ec45f"
      },
      "source": [
        "lda.components_.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10, 5000)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C2sM9NivF1uQ",
        "colab_type": "code",
        "colab": {},
        "outputId": "434a2372-75a3-4d34-c810-5ed69b3eee40"
      },
      "source": [
        "n_top_words = 5\n",
        "feature_names = count.get_feature_names()\n",
        "for topic_idx, topic in enumerate(lda.components_):\n",
        "    print('토픽 %d:' % (topic_idx + 1))\n",
        "    print(' '.join([feature_names[i] for i in topic.argsort() [:-n_top_words - 1: -1]]))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "토픽 1:\n",
            "worst minutes awful script stupid\n",
            "토픽 2:\n",
            "family mother father children girl\n",
            "토픽 3:\n",
            "american war dvd music tv\n",
            "토픽 4:\n",
            "human audience cinema art sense\n",
            "토픽 5:\n",
            "police guy car dead murder\n",
            "토픽 6:\n",
            "horror house sex girl woman\n",
            "토픽 7:\n",
            "role performance comedy actor performances\n",
            "토픽 8:\n",
            "series episode war episodes tv\n",
            "토픽 9:\n",
            "book version original read novel\n",
            "토픽 10:\n",
            "action fight guy guys cool\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g4jZVj_GF1uS",
        "colab_type": "code",
        "colab": {},
        "outputId": "fbf69a65-c2df-47f3-ed04-64d24398a4c5"
      },
      "source": [
        "horror = X_topics[:, 5].argsort()[::-1]\n",
        "for iter_idx, movie_idx in enumerate(horror[:3]):\n",
        "    print('\\n공포영화 #%d' % (iter_idx + 1))\n",
        "    print(df['review'][movie_idx][:300], '...')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "공포영화 #1\n",
            "House of Dracula works from the same basic premise as House of Frankenstein from the year before; namely that Universal's three most famous monsters; Dracula, Frankenstein's Monster and The Wolf Man are appearing in the movie together. Naturally, the film is rather messy therefore, but the fact that ...\n",
            "\n",
            "공포영화 #2\n",
            "Okay, what the hell kind of TRASH have I been watching now? \"The Witches' Mountain\" has got to be one of the most incoherent and insane Spanish exploitation flicks ever and yet, at the same time, it's also strangely compelling. There's absolutely nothing that makes sense here and I even doubt there  ...\n",
            "\n",
            "공포영화 #3\n",
            "<br /><br />Horror movie time, Japanese style. Uzumaki/Spiral was a total freakfest from start to finish. A fun freakfest at that, but at times it was a tad too reliant on kitsch rather than the horror. The story is difficult to summarize succinctly: a carefree, normal teenage girl starts coming fac ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yi4v6vWhF1uU",
        "colab_type": "text"
      },
      "source": [
        "# chapter 9\n",
        "# 웹 애플리케이션에 머신러닝 모델 내장"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z8e0e335F1uU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "import os\n",
        "\n",
        "# 웹 애플리케이션에 필요한 파일과 데이터를 저장할 movieclassifier디렉토리 생성\n",
        "# pkl_objects는 서브디렉토리: python 객체를 저장함\n",
        "dest = os.path.join('movieclassifier', 'pkl_objects')\n",
        "if not os.path.exists(dest):\n",
        "    os.makedirs(dest)\n",
        "    \n",
        "# dump메소드로 불용어를 직렬화 하여 저장\n",
        "pickle.dump(stop, open(os.path.join(dest, 'stopwords.pkl'), 'wb'), protocol = 4)\n",
        "pickle.dump(clf, open(os.path.join(dest, 'classifier.pkl'), 'wb'), protocol = 4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YCCeTb5uF1uX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_extraction.text import HashingVectorizer\n",
        "import re\n",
        "import os\n",
        "import pickle\n",
        "\n",
        "cur_dir = os.path.dirname('C:\\\\Users\\\\silve\\Desktop\\\\movieclassifier\\\\pkl_objects')\n",
        "stop = pickle.load(open(os.path.join(cur_dir, 'pkl_objects', 'stopwords.pkl'), 'rb'))\n",
        "\n",
        "def tokenizer(text):\n",
        "    text = re.sub('<[^>]*>', '', text)\n",
        "    emoticons = re.findall('(?::|;|=)(?:-)?(?:\\)|\\(|D|P)', text.lower())\n",
        "    \n",
        "    text = re.sub('[\\W]+', ' ', text.lower()) + ' '.join(emoticons).replace('-','')\n",
        "    tokenized = [w for w in text.split() if w not in stop]\n",
        "    \n",
        "    return tokenized\n",
        "\n",
        "vect = HashingVectorizer(decode_error = 'ignore', n_features = 2 ** 21, preprocessor = None, tokenizer = tokenizer)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hxQwELWIF1ua",
        "colab_type": "code",
        "colab": {},
        "outputId": "d45a54f1-7014-4628-9daa-147d34af57d9"
      },
      "source": [
        "!pip install vectors"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: vectors in c:\\users\\silve\\anaconda3\\envs\\venv\\lib\\site-packages (1.0.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CM2JyOVEF1uc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 분류기 복원\n",
        "import pickle\n",
        "import re\n",
        "import os\n",
        "\n",
        "clf = pickle.load(open(os.path.join(cur_dir, 'pkl_objects', 'classifier.pkl'), 'rb'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-FKwRX7qF1ue",
        "colab_type": "code",
        "colab": {},
        "outputId": "05ee5089-1da1-4189-ed3e-18b52f8c0075"
      },
      "source": [
        "# 문서샘플 전처리 후 예측\n",
        "import numpy as np\n",
        "\n",
        "label = {0: '음성', 1: '양성'}\n",
        "\n",
        "example = ['I love this movie']\n",
        "X = vect.transform(example)\n",
        "\n",
        "print('예측: %s \\n확률: %.2f%%' % (label[clf.predict(X)[0]], np.max(clf.predict_proba(X)) * 100))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "예측: 양성 \n",
            "확률: 81.44%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TnBj_cn_F1uh",
        "colab_type": "text"
      },
      "source": [
        "# 데이터를 저장하기 위한 SQLite"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Sr_KEKFF1uh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sqlite3\n",
        "\n",
        "conn = sqlite3.connect('reviews.sqlite') # connect 메소드를 이용한 파일연결\n",
        "c = conn.cursor()# curcor 메소드를 이용하여 코드조작\n",
        "\n",
        "c.execute('DROP TABLE IF EXISTS review_db') #rebiew_db생성\n",
        "c.execute('CREATE TABLE review_db' \\\n",
        "         '(review TEXT, sentiment INTEGER, date TEXT)')\n",
        "\n",
        "example1 = 'I love this movie'\n",
        "c.execute(\"INSERT INTO review_db\"\\\n",
        "         \" (review, sentiment, date) VALUES\"\\\n",
        "         \" (?, ?, DATETIME('now'))\", (example1, 1))\n",
        "\n",
        "example2 = 'I disliked this movie'\n",
        "c.execute(\"INSERT INTO review_db\"\\\n",
        "         \" (review, sentiment, date) VALUES\"\\\n",
        "         \" (?, ?, DATETIME('now'))\", (example2, 0))\n",
        "\n",
        "conn.commit()\n",
        "conn.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IVhwi9EJF1uk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "conn = sqlite3.connect('reviews.sqlite')\n",
        "c = conn.cursor()\n",
        "c.execute(\"SELECT * FROM review_db WHERE date\"\\\n",
        "         \" BETWEEN '2017-01-01 00:00:00' AND DATETIME('now')\")\n",
        "results = c.fetchall()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0iPGdv1OF1um",
        "colab_type": "code",
        "colab": {},
        "outputId": "ca337f23-9af1-4426-a8aa-822834d81c91"
      },
      "source": [
        "conn.close()\n",
        "print(results)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('I love this movie', 1, '2020-03-02 07:08:44'), ('I disliked this movie', 0, '2020-03-02 07:08:44')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B5aFnOCFF1up",
        "colab_type": "text"
      },
      "source": [
        "# 플라스크 웹 애플리케이션"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R-YeCykgF1uq",
        "colab_type": "code",
        "colab": {},
        "outputId": "59c967c8-1578-4c87-8035-0fdef2d80f71"
      },
      "source": [
        "!pip install flask"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: flask in c:\\users\\silve\\anaconda3\\envs\\venv\\lib\\site-packages (1.1.1)\n",
            "Requirement already satisfied: Jinja2>=2.10.1 in c:\\users\\silve\\anaconda3\\envs\\venv\\lib\\site-packages (from flask) (2.10.3)\n",
            "Requirement already satisfied: click>=5.1 in c:\\users\\silve\\anaconda3\\envs\\venv\\lib\\site-packages (from flask) (7.0)\n",
            "Requirement already satisfied: Werkzeug>=0.15 in c:\\users\\silve\\anaconda3\\envs\\venv\\lib\\site-packages (from flask) (0.16.0)\n",
            "Requirement already satisfied: itsdangerous>=0.24 in c:\\users\\silve\\anaconda3\\envs\\venv\\lib\\site-packages (from flask) (1.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\silve\\anaconda3\\envs\\venv\\lib\\site-packages (from Jinja2>=2.10.1->flask) (1.1.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PiEW-mYWF1ur",
        "colab_type": "code",
        "colab": {},
        "outputId": "7e81e0de-3b09-403f-9f9b-d40efa5ff705"
      },
      "source": [
        "''' 디렉터리 구조\n",
        "1st_flask_app_1/\n",
        "    app.py\n",
        "    templates/\n",
        "        first_app.html\n",
        "'''\n",
        "from flask import Flask, render_template\n",
        "\n",
        "app = Flask(__name__)\n",
        "@app.route('/')\n",
        "def index():\n",
        "    return render_template('first_app.html')\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    app.run()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " * Serving Flask app \"__main__\" (lazy loading)\n",
            " * Environment: production\n",
            "   WARNING: This is a development server. Do not use it in a production deployment.\n",
            "   Use a production WSGI server instead.\n",
            " * Debug mode: off\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WSe1eELaF1ut",
        "colab_type": "code",
        "colab": {},
        "outputId": "246804ad-ff77-47cf-bfc5-1edf7a082517"
      },
      "source": [
        "python app.py"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "invalid syntax (<ipython-input-49-b851947b46d7>, line 1)",
          "traceback": [
            "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-49-b851947b46d7>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    python app.py\u001b[0m\n\u001b[1;37m             ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TLOc2RqUF1uv",
        "colab_type": "code",
        "colab": {},
        "outputId": "b6d1c3b6-dacc-4ee3-dc77-4089c165465b"
      },
      "source": [
        "!pip install wtforms"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting wtforms\n",
            "  Downloading WTForms-2.2.1-py2.py3-none-any.whl (166 kB)\n",
            "Installing collected packages: wtforms\n",
            "Successfully installed wtforms-2.2.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Hs4j97dF1uw",
        "colab_type": "code",
        "colab": {},
        "outputId": "24a0f663-6a01-4d70-9833-aaafce36fe0a"
      },
      "source": [
        "'''\n",
        "1st_flask_app_2/\n",
        "    app.py\n",
        "    static/\n",
        "        style.css\n",
        "    templates/\n",
        "        _forhelpers.html\n",
        "        first_app.html\n",
        "        hello.html'''\n",
        "from flask import Flask, render_template, request\n",
        "from wtforms import Form, TextAreaField, validators\n",
        "\n",
        "app = Flask(__name__)\n",
        "\n",
        "class HelloForm(Form):\n",
        "    sayhellp = TextAreaField('', [validators.DataRequired()])\n",
        "    \n",
        "@app.route('/')\n",
        "def index():\n",
        "    form = HelloForm(request.form)\n",
        "    return render_template('first_app.html', form = form)\n",
        "\n",
        "@app.route('/hello', methods = ['POST'])\n",
        "def hello():\n",
        "    form = HelloFrom(request.form)\n",
        "    if request.method == 'POST' and form.validate():\n",
        "        name = request.form['sayhello']\n",
        "        return render_template('hello.html', name = name)\n",
        "    return render_template('first_app.html', form = form)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    app.run(debug = True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " * Serving Flask app \"__main__\" (lazy loading)\n",
            " * Environment: production\n",
            "   WARNING: This is a development server. Do not use it in a production deployment.\n",
            "   Use a production WSGI server instead.\n",
            " * Debug mode: on\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " * Restarting with stat\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "SystemExit",
          "evalue": "1",
          "traceback": [
            "An exception has occurred, use %tb to see the full traceback.\n",
            "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 1\n"
          ]
        },
        {
          "output_type": "stream",
          "text": [
            "C:\\Users\\silve\\Anaconda3\\envs\\venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3327: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
            "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YUo1126OF1uy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Jinja 템플릿을 이용하여 매크로 구현\n",
        "{% macro render_field(field) %}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a9U-jbwRF1u0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lBTo5BwhF1u1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}