{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Neural_Networks.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPkqLHv1oMcZjIMEhj0gmWT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/silverstar0727/study-/blob/master/Neural_Networks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JBNbbISeckvZ",
        "colab_type": "text"
      },
      "source": [
        "## 신경망(Neural Network)\n",
        "torch.nn 패키지를 이용하여 신경망을 생성하며, 여기서 앞서 배운 autograd를 사용한다. nn.Module은 layer와 output을 반환하는 forward메서드를 포함한다.\n",
        "\n",
        "mnist에서 숫자 이미지를 분류하는 신경망의 예제를 통해 공부해보자.\n",
        "\n",
        "우선 신경망의 일반적인 학습과정은 다음과 같다\n",
        "* 학습 가능한 매개변수를 갖는 신경망을 정의한다.\n",
        "* 데이터셋 입력을 반복한다.\n",
        "* 입력을 신경망에서 전파(process)한다.\n",
        "* 손실(loss)에 대해 계산한다\n",
        "* gradient를 신경망의 배개변수들에 역전파한다\n",
        "* 신경망의 가중치를 갱신한다(weight = prev_weight - learning rate * gradient)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TzwhfUbdaf06",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "outputId": "98b0fdf8-dbc0-414b-b336-fa0911eedf17"
      },
      "source": [
        "# 신경망 정의하기\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class Net(nn.Module): # nn.Module을 상속받음\n",
        "  def __init__(self):\n",
        "    super(Net, self).__init__()\n",
        "    # 1개의 input image channel, 6개의 output channels, 3by3 square convolution\n",
        "    # kernel\n",
        "    self.conv1 = nn.Conv2d(1, 6, 3)\n",
        "    self.conv2 = nn.Conv2d(6, 16, 3)\n",
        "    # an affine operation: y = Wx + b\n",
        "    self.fc1 = nn.Linear(16 * 6 * 6, 120) # 6by6 from image dimension\n",
        "    self.fc2 = nn.Linear(120, 84)\n",
        "    self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "  def forward(self, x):\n",
        "    # Max pooling over a (2, 2) window\n",
        "    x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
        "    # window가 정사각형이라면 하나의 숫자로 특정할 수 있다\n",
        "    x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
        "    x = x.view(-1, self.num_flat_features(x))\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = F.relu(self.fc2(x))\n",
        "    x = self.fc3(x)\n",
        "    return x\n",
        "\n",
        "  def num_flat_features(self, x):\n",
        "    size = x.size()[1:] # batch 차원을 제외한 모든 차원\n",
        "    num_features = 1\n",
        "    for s in size:\n",
        "      num_features *= s\n",
        "    return num_features\n",
        "\n",
        "net = Net()\n",
        "print(net)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Net(\n",
            "  (conv1): Conv2d(1, 6, kernel_size=(3, 3), stride=(1, 1))\n",
            "  (conv2): Conv2d(6, 16, kernel_size=(3, 3), stride=(1, 1))\n",
            "  (fc1): Linear(in_features=576, out_features=120, bias=True)\n",
            "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
            "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E0wou8VSafyy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "c9039b21-38b0-4db7-bbed-85af414ea171"
      },
      "source": [
        "# 학습 가능한 매개변수는 net.parameters()에 의해 반환\n",
        "params = list(net.parameters())\n",
        "print(len(params))\n",
        "print(params[0].size())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10\n",
            "torch.Size([6, 1, 3, 3])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Fs44n5jafw2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "2bc6f76a-99c5-4b57-c9ed-8f6630283b03"
      },
      "source": [
        "# 32by32 데이터 셋을 입력\n",
        "input = torch.randn(1, 1, 32, 32)\n",
        "out = net(input)\n",
        "print(out)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 0.0680,  0.1066, -0.1343, -0.0233,  0.0344,  0.1344, -0.0366,  0.0966,\n",
            "          0.0643,  0.0446]], grad_fn=<AddmmBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DX63oX9vafun",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 모든 매개변수의 변화도 버퍼를 0으로 하고 무작위 값으로 역전파 진행\n",
        "net.zero_grad()\n",
        "out.backward(torch.randn(1, 10))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C2UjTze9y2iM",
        "colab_type": "text"
      },
      "source": [
        "## Loss Function\n",
        "간단한 손실 함수로 MSE(mean-squared error)를 nn.MSEloss가 지원"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-azdpHpdytAV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "85a7cb27-374f-408f-f5c5-cdebe8628315"
      },
      "source": [
        "output = net(input)\n",
        "target = torch.randn(10)\n",
        "target = target.view(1, -1)\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "loss = criterion(output, target)\n",
        "print(loss)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(0.9374, grad_fn=<MseLossBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cMSD5vMxzVnv",
        "colab_type": "text"
      },
      "source": [
        "## 연산 순서\n",
        "\n",
        "      input -> conv2d -> relu -> maxpool2d -> conv2d -> relu -> maxpool2d\n",
        "      -> view -> linear -> relu -> linear -> relu -> linear\n",
        "      -> MSELoss\n",
        "      -> loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UoV4_BIuzNjk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "0599418a-1b4d-4ada-895b-d64c2ece7133"
      },
      "source": [
        "print(loss.grad_fn)\n",
        "print(loss.grad_fn.next_functions[0][0])\n",
        "print(loss.grad_fn.next_functions[0][0].next_functions[0][0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<MseLossBackward object at 0x7f735b5e6080>\n",
            "<AddmmBackward object at 0x7f735b5e60b8>\n",
            "<AccumulateGrad object at 0x7f735b5e6080>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q8YTNOX60BdW",
        "colab_type": "text"
      },
      "source": [
        "## 역전파((back propagation)\n",
        "loss.backward()를 통해 역전파를 진행하는데, 기존의 변화도를 없애지 않으면 변화가 누적되기 때문에 없애야 한다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0b_lkOEWzxWt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "babef5ae-c063-48cc-d212-c00ac70f97e1"
      },
      "source": [
        "net.zero_grad() # 모든 파라미터에 대한 gradient buffer를 0으로 조정\n",
        "\n",
        "print('conv1.bias.grad before backward')\n",
        "print(net.conv1.bias.grad)\n",
        "\n",
        "loss.backward()\n",
        "\n",
        "print('conv1.bias.grad after backward')\n",
        "print(net.conv1.bias.grad)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "conv1.bias.grad before backward\n",
            "tensor([0., 0., 0., 0., 0., 0.])\n",
            "conv1.bias.grad after backward\n",
            "tensor([-0.0185,  0.0143,  0.0046, -0.0002, -0.0012,  0.0109])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qXjsyHgW0o-H",
        "colab_type": "text"
      },
      "source": [
        "## 가중치 갱신\n",
        "간단한 모델의 SGD(Stochastic Gradient Descent)를 활용\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6MMnt12n0hFx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 직접 구현\n",
        "learning_rate = 0.01\n",
        "for f in net.parameters():\n",
        "  f.data.sub_(f.grad.data * learning_rate)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k7aKnvIm587M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# torch.optim패키지를 이용\n",
        "import torch.optim as optim\n",
        "\n",
        "optimizer = optim.SGD(net.parameters(), lr = 0.01)\n",
        "\n",
        "# training loop\n",
        "optimizer.zero_grad() # zero the gradient buffer(수동으로 해야됨)\n",
        "output = net(input)\n",
        "loss = criterion(output, target)\n",
        "loss.backward()\n",
        "optimizer.step() # does the update"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CbysHsM36TjJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
