{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Auto_Grad.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPinxDaeYaCIaOM5X8q4Qjf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/silverstar0727/study-/blob/master/Auto_Grad.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E6Fag8o9t5My",
        "colab_type": "text"
      },
      "source": [
        "## AUTOGRAD(자동미분)\n",
        "pytorch의 모든 신경망의 중심에는 autograd패키지가 존재한다. 이는 tensor의 모든 연산에 대해 자동 미분을 제공한다. 실행에 기반한 정의(define-by-run) 프레임워크로 코드를 어떻게 작성하는지에 따라 역전파가 정의된다는 것을 의미하고, 역전파는 학습 과정의 단계마다 달라진다.\n",
        "\n",
        "## Tensor\n",
        "torch.Tensor 클래스에서 .requires_grad 속성을 True로 설정하면 그 tensor에서 이뤄진 모든 연산을 추적(track)하기 시작한다. 계산이 끝나면 .backward()를 호출하여 gradient를 자동으로 계산할 수 있으며, .grad속성에 누적된다.\n",
        "\n",
        "이를 중단하기 위해서는 .detach()를 사용한다. 코드블럭을 with torch.no_grad():로 감쌀 수 있는데, gradient는 필요 없지만, 학습 가능한 매개변수를 갖는 모델을 평가할 때 유용하다.\n",
        "\n",
        "* Function\n",
        "\n",
        "tensor와 Function은 서로 연결되어 있는데 모든 연산과정을 부호화(encode)하여 acycle graph를 생성한다.\n",
        "\n",
        "tensor의 .graph_fn 속성은 tensor를 생성한 Function속성을 참조한다. 그러나 사용자가 만든 tensor의 .graph_fn 값은 None이다.\n",
        "\n",
        "도함수를 계산하기 위해서는 .backward()를 호출하고 tensor가 여러 요소를 갖고 있을 경우에는 tensor의 모양을 gradient의 인자로 지정할 필요가 존재한다"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iif0K0NbqHpS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch"
      ],
      "execution_count": 194,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "USLHoNJu0PvV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "92d02500-6fca-4f4a-ecc9-4ac0c0ac2a16"
      },
      "source": [
        "# x에서 이뤄진 연산을 track하도록 True로 설정\n",
        "x = torch.ones(2, 2, requires_grad = True)\n",
        "print(x)"
      ],
      "execution_count": 195,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[1., 1.],\n",
            "        [1., 1.]], requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iM0bqByM0ey4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "a72777ff-70ce-4e14-b808-43e48df83f14"
      },
      "source": [
        "y = x + 2\n",
        "print(y)"
      ],
      "execution_count": 196,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[3., 3.],\n",
            "        [3., 3.]], grad_fn=<AddBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qJeL5MCF0gTY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "6f194c5b-da99-4984-b802-442dac726f43"
      },
      "source": [
        "# y는 사용자 지정함수가 아니므로 grad_fn을 갖고, x는 사용자 지정함수이므로 None값을 갖는다.\n",
        "print(y.grad_fn, x.grad_fn)"
      ],
      "execution_count": 197,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<AddBackward0 object at 0x7f719dbcf780> None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "byXUGNj20tfj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "22e993ca-ce38-4baf-a964-d006480f850b"
      },
      "source": [
        "z = y * y * 3\n",
        "out = z.mean()\n",
        "\n",
        "print(z, out)"
      ],
      "execution_count": 198,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[27., 27.],\n",
            "        [27., 27.]], grad_fn=<MulBackward0>) tensor(27., grad_fn=<MeanBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TVW5uPl405f-",
        "colab_type": "text"
      },
      "source": [
        ".requires_grad _ 는 기존의 tensor의 requies_grad 값을 in-place하여 변경함\n",
        "\n",
        "입력값이 지정되지 않을 경우 기본 값은 False"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XM7YWQ-_0zU7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "95adc8a0-dcc5-456f-a487-c4b4243ac0e5"
      },
      "source": [
        "a = torch.randn(2, 2)\n",
        "a = ((a * 3) / (a - 1))\n",
        "print(a.requires_grad)\n",
        "a.requires_grad_(True)\n",
        "print(a.requires_grad)\n",
        "b = (a * a).sum()\n",
        "print(b.grad_fn)"
      ],
      "execution_count": 199,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "False\n",
            "True\n",
            "<SumBackward0 object at 0x7f719dca4048>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yk68S_SX1XDX",
        "colab_type": "text"
      },
      "source": [
        "## Gradient\n",
        "역전파(backprop)에서 out은 하나의 스칼라 값(mean을 취했으므로)을 가지고 있기 때문에 out.backward()는 out.backward(torch.tensor(1.))과 동일하다\n",
        "\n",
        "여기서 x는 앞서 $y = x + 2$ $z = y \\times y \\times 3$ out = z.mean()을 통해  변환을 거쳤으므로, $d(out) \\over dx$를 출력한 x.grad는 4.5에 해당한다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OkkFXpPS1Ksf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "out.backward()"
      ],
      "execution_count": 200,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hZFtF99R1pUo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "9abc580e-7e38-4f20-e73a-7b2a5433983d"
      },
      "source": [
        "print(x.grad)"
      ],
      "execution_count": 201,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[4.5000, 4.5000],\n",
            "        [4.5000, 4.5000]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jWQJjE9A_tKU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "18a0f6b4-6e35-4943-88dc-441a864717f3"
      },
      "source": [
        "x = torch.randn(3, requires_grad = True)\n",
        "\n",
        "y = x * 2\n",
        "while y.data.norm() < 1000:\n",
        "  y = y * 2\n",
        "print(y)"
      ],
      "execution_count": 205,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([ -210.7840, -1391.3506,  1079.1760], grad_fn=<MulBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZP0SJzNrK02Q",
        "colab_type": "text"
      },
      "source": [
        "y가 스칼라 값이 아니기 때문에 torch.autograd는 전체 야코비안을 계산할 수 없다. 그러나, vector-jacobian곱은 backward의 인자로 받아 계산이 가능하다"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eBySOrWuKhtx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "e5a9c5a8-54c1-4af9-e30e-eae683a72d2d"
      },
      "source": [
        "v = torch.tensor([0.1, 1.0, 0.0001], dtype = torch.float)\n",
        "y.backward(v)\n",
        "print(x.grad)"
      ],
      "execution_count": 206,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([2.0480e+02, 2.0480e+03, 2.0480e-01])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CQnNV6_ELaQb",
        "colab_type": "text"
      },
      "source": [
        "코드블럭을 감싸서 기록의 추적을 막을 수 있음"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fruokR6zKx1D",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "8e37ccd4-79f0-4a50-bb01-134e07f1c876"
      },
      "source": [
        "print(x.requires_grad)\n",
        "print((x**2).requires_grad)\n",
        "\n",
        "with torch.no_grad():\n",
        "  print((x**2).requires_grad)"
      ],
      "execution_count": 208,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True\n",
            "True\n",
            "False\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jr9hhDQzLd9n",
        "colab_type": "text"
      },
      "source": [
        ".detach()를 호출하여 내용물은 같지만 require_grad가 다른 새로운 tensor를 가져올 수 있음"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RXbp_iraLSj6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "05e0e594-55d9-402c-aa6b-e7ac3fecf4e2"
      },
      "source": [
        "print(x.requires_grad)\n",
        "y = x.detach()\n",
        "print(y.requires_grad)\n",
        "print(x.eq(y).all())"
      ],
      "execution_count": 209,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True\n",
            "False\n",
            "tensor(True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vr7PIJfWLspX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}